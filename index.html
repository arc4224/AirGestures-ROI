<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>TeleAssist-ROI</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheet/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheet/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">TeleAssist-ROI</h1>
      <h2 class="project-tagline">Hand Gesture based Region Marking for Tele-support using Wearables</h2>
      <a href="https://youtu.be/3LYjsKIqUAE" class="btn">Demo Video</a>
     
    </section>

    <section class="main-content">
      <h3>
<a id="welcome-to-telepresence-roi" class="anchor" href="#welcome-to-telepresence-roi" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to TeleAssist</h3>

<p>Wearable AR devices are being explored in many applications,are being explored in many applications for visualizing real-time contextual information. More importantly, these devices can also be used in tele-assistance from remote sites when on-field operators require off-field expert’s guidance for trouble-shooting. For an effective communication, touchless hand gestures are the most intuitive to select a Region Of Interest (ROI) like defective parts in a machine, through a wearable. This paper presents a hand gestural interaction method to localize the ROI in First Person View (FPV). The region selected using freehand sketching gestures is highlighted to the remote server setup for expert’s advice. Novelty of the proposed method include (a) touchless finger-based gesture recognition algorithm that runs on smartphones, which can be used with wearable frugal modality <a href="https://vr.google.com/cardboard/">Google Cardboard</a> and <a href="http://wearality.com/">Wearality</a>, (b) reducing the network latency and achieving real-time performance by on-board implementation of recognition module.</p>

<h3>
<a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Idea</h3>

<p><img src="https://github.com/arc4224/AirGesturesROI/blob/master/img/Setup.png?raw=true?" alt="Proposed Method "></p>

<p>We  present an  approach  for  marker-less  and  real-time touch-less gestures to mark ROI on wearables in FPV by proposing a novel two  stage  sequential  gesture  recognition  method as shown in the demo video.   First,  we  detect  a dynamic  gesture which involves detecting the presence of a stable hand , then raising the index finger with the rest of the fist closed(termed as point gesture) to trigger ROI Selection. This is followed by another dynamic gesture involving moving point gesture around the object of interest.   Our  approach  is  particularly  suitable  as  most  of  the smartphones available in the market are not equipped with built-in depth sensor posing additional challenges. The main blocks of the algorithm are: (i)point gesture detection, (ii) ROI selection, (iii) ROI tracking, and (iv) subsequent updating of bounding box around the ROI. Skin pixel detection followed by largest contour segmentation gives the hand region in the user's FOV. The fingertip is computed as the farthest point from the centroid of hand. After finger  tip  detection, a closed contour is drawn following the locus of the detected fingertip,  in the sequence of frames. After  the  ROI  is  selected,  the  resultant  bounding  box using an approach based on Shi-Tomasi feature points and optical flow vectors. The unreliable trajectories of the feature points are eliminated using the Forward-Backward Error method. 
We conducted experiments on  industrial which  demonstrates  that  the problem identification with our method of ROI highlighting gets faster by 60%, in comparison to sole audio instructions. </p>

<h3>
<a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo Video</h3>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/3LYjsKIqUAE" frameborder="0" allowfullscreen></iframe>
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/arc4224/AirGestures-ROI">TeleAssist-ROI</a> is maintained by <a href="https://github.com/arc4224">arc4224</a>.</span>

      </footer>

    </section>

  
  </body>
</html>
